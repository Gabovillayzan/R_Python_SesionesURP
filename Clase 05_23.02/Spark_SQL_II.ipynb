{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando Session Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.Builder().appName(\"Prueba1\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesta de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "departamentos = spark.read.csv(\"../data/HR/departamentos.dsv\", header=True, sep=';', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DEPARTMENT_ID', 'int'),\n",
       " ('DEPARTMENT_NAME', 'string'),\n",
       " ('MANAGER_ID', 'int'),\n",
       " ('LOCATION_ID', 'int')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "departamentos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+----------+-----------+\n",
      "|DEPARTMENT_ID|     DEPARTMENT_NAME|MANAGER_ID|LOCATION_ID|\n",
      "+-------------+--------------------+----------+-----------+\n",
      "|           10|      Administration|       200|       1700|\n",
      "|           20|           Marketing|       201|       1800|\n",
      "|           30|          Purchasing|       114|       1700|\n",
      "|           40|     Human Resources|       203|       2400|\n",
      "|           50|            Shipping|       121|       1500|\n",
      "|           60|                  IT|       103|       1400|\n",
      "|           70|    Public Relations|       204|       2700|\n",
      "|           80|               Sales|       145|       2500|\n",
      "|           90|           Executive|       100|       1700|\n",
      "|          100|             Finance|       108|       1700|\n",
      "|          110|          Accounting|       205|       1700|\n",
      "|          120|            Treasury|      null|       1700|\n",
      "|          130|       Corporate Tax|      null|       1700|\n",
      "|          140|  Control And Credit|      null|       1700|\n",
      "|          150|Shareholder Services|      null|       1700|\n",
      "|          160|            Benefits|      null|       1700|\n",
      "|          170|       Manufacturing|      null|       1700|\n",
      "|          180|        Construction|      null|       1700|\n",
      "|          190|         Contracting|      null|       1700|\n",
      "|          200|          Operations|      null|       1700|\n",
      "+-------------+--------------------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "departamentos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "empleados = spark.read.csv('hdfs://localhost:54310/datos/empleados.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EMPLOYEE_ID', 'int'),\n",
       " ('FIRST_NAME', 'string'),\n",
       " ('LAST_NAME', 'string'),\n",
       " ('EMAIL', 'string'),\n",
       " ('PHONE_NUMBER', 'string'),\n",
       " ('HIRE_DATE', 'string'),\n",
       " ('JOB_ID', 'string'),\n",
       " ('SALARY', 'int'),\n",
       " ('COMMISSION_PCT', 'int'),\n",
       " ('MANAGER_ID', 'int'),\n",
       " ('DEPARTMENT_ID', 'int')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empleados.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|EMPLOYEE_ID|FIRST_NAME|LAST_NAME|   EMAIL|PHONE_NUMBER|HIRE_DATE|    JOB_ID|SALARY|COMMISSION_PCT|MANAGER_ID|DEPARTMENT_ID|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "|        100|    Steven|     King|   SKING|515.123.4567| 17/06/03|   AD_PRES| 24000|          null|      null|           90|\n",
      "|        101|     Neena|  Kochhar|NKOCHHAR|515.123.4568| 21/09/05|     AD_VP| 17000|          null|       100|           90|\n",
      "|        102|       Lex|  De Haan| LDEHAAN|515.123.4569| 13/01/01|     AD_VP| 17000|          null|       100|           90|\n",
      "|        103| Alexander|   Hunold| AHUNOLD|590.423.4567| 03/01/06|   IT_PROG|  9000|          null|       102|           60|\n",
      "|        104|     Bruce|    Ernst|  BERNST|590.423.4568| 21/05/07|   IT_PROG|  6000|          null|       103|           60|\n",
      "|        105|     David|   Austin| DAUSTIN|590.423.4569| 25/06/05|   IT_PROG|  4800|          null|       103|           60|\n",
      "|        106|     Valli|Pataballa|VPATABAL|590.423.4560| 05/02/06|   IT_PROG|  4800|          null|       103|           60|\n",
      "|        107|     Diana|  Lorentz|DLORENTZ|590.423.5567| 07/02/07|   IT_PROG|  4200|          null|       103|           60|\n",
      "|        108|     Nancy|Greenberg|NGREENBE|515.124.4569| 17/08/02|    FI_MGR| 12008|          null|       101|          100|\n",
      "|        109|    Daniel|   Faviet| DFAVIET|515.124.4169| 16/08/02|FI_ACCOUNT|  9000|          null|       108|          100|\n",
      "+-----------+----------+---------+--------+------------+---------+----------+------+--------------+----------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empleados.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_trabajos = spark.read.csv(\"../data/HR/historico_trabajos.dsv\", header=True, sep='|', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EMPLOYEE_ID', 'int'),\n",
       " ('START_DATE', 'string'),\n",
       " ('END_DATE', 'string'),\n",
       " ('JOB_ID', 'string'),\n",
       " ('DEPARTMENT_ID', 'int')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_trabajos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------+----------+-------------+\n",
      "|EMPLOYEE_ID|START_DATE|END_DATE|    JOB_ID|DEPARTMENT_ID|\n",
      "+-----------+----------+--------+----------+-------------+\n",
      "|        102|  13/01/01|24/07/06|   IT_PROG|           60|\n",
      "|        101|  21/09/97|27/10/01|AC_ACCOUNT|          110|\n",
      "|        101|  28/10/01|15/03/05|    AC_MGR|          110|\n",
      "|        201|  17/02/04|19/12/07|    MK_REP|           20|\n",
      "|        114|  24/03/06|31/12/07|  ST_CLERK|           50|\n",
      "|        122|  01/01/07|31/12/07|  ST_CLERK|           50|\n",
      "|        200|  17/09/95|17/06/01|   AD_ASST|           90|\n",
      "|        176|  24/03/06|31/12/06|    SA_REP|           80|\n",
      "|        176|  01/01/07|31/12/07|    SA_MAN|           80|\n",
      "|        200|  01/07/02|31/12/06|AC_ACCOUNT|           90|\n",
      "+-----------+----------+--------+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist_trabajos.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "locaciones = spark.read.csv(\"../data/HR/locaciones.tsv\", header=True, sep='\\t', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LOCATION_ID', 'int'),\n",
       " ('STREET_ADDRESS', 'string'),\n",
       " ('POSTAL_CODE', 'string'),\n",
       " ('CITY', 'string'),\n",
       " ('STATE_PROVINCE', 'string'),\n",
       " ('COUNTRY_ID', 'string')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locaciones.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+-----------+-------------------+----------------+----------+\n",
      "|LOCATION_ID|      STREET_ADDRESS|POSTAL_CODE|               CITY|  STATE_PROVINCE|COUNTRY_ID|\n",
      "+-----------+--------------------+-----------+-------------------+----------------+----------+\n",
      "|       1000|1297 Via Cola di Rie|      00989|               Roma|            null|        IT|\n",
      "|       1100|93091 Calle della...|      10934|             Venice|            null|        IT|\n",
      "|       1200|    2017 Shinjuku-ku|       1689|              Tokyo|Tokyo Prefecture|        JP|\n",
      "|       1300|     9450 Kamiya-cho|       6823|          Hiroshima|            null|        JP|\n",
      "|       1400| 2014 Jabberwocky Rd|      26192|          Southlake|           Texas|        US|\n",
      "|       1500| 2011 Interiors Blvd|      99236|South San Francisco|      California|        US|\n",
      "|       1600|      2007 Zagora St|      50090|    South Brunswick|      New Jersey|        US|\n",
      "|       1700|     2004 Charade Rd|      98199|            Seattle|      Washington|        US|\n",
      "|       1800|     147 Spadina Ave|    M5V 2L7|            Toronto|         Ontario|        CA|\n",
      "|       1900|     6092 Boxwood St|    YSW 9T2|         Whitehorse|           Yukon|        CA|\n",
      "+-----------+--------------------+-----------+-------------------+----------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "locaciones.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paises = spark.read.csv(\"../data/HR/paises.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('COUNTRY_ID', 'string'), ('COUNTRY_NAME', 'string'), ('REGION_ID', 'int')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paises.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+\n",
      "|COUNTRY_ID|COUNTRY_NAME|REGION_ID|\n",
      "+----------+------------+---------+\n",
      "|        AR|   Argentina|        2|\n",
      "|        AU|   Australia|        3|\n",
      "|        BE|     Belgium|        1|\n",
      "|        BR|      Brazil|        2|\n",
      "|        CA|      Canada|        2|\n",
      "|        CH| Switzerland|        1|\n",
      "|        CN|       China|        3|\n",
      "|        DE|     Germany|        1|\n",
      "|        DK|     Denmark|        1|\n",
      "|        EG|       Egypt|        4|\n",
      "+----------+------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paises.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regiones = spark.read.csv(\"../data/HR/regiones.txt\", header=True, sep='\\t', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('REGION_ID', 'int'), ('REGION_NAME', 'string')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regiones.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+\n",
      "|REGION_ID|         REGION_NAME|\n",
      "+---------+--------------------+\n",
      "|        1|              Europe|\n",
      "|        2|            Americas|\n",
      "|        3|                Asia|\n",
      "|        4|Middle East and A...|\n",
      "+---------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regiones.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trabajos = spark.read.csv(\"../data/HR/trabajos.dsv\", header=True, sep=':', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('JOB_ID', 'string'),\n",
       " ('JOB_TITLE', 'string'),\n",
       " ('MIN_SALARY', 'int'),\n",
       " ('MAX_SALARY', 'int')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trabajos.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------+----------+\n",
      "|    JOB_ID|           JOB_TITLE|MIN_SALARY|MAX_SALARY|\n",
      "+----------+--------------------+----------+----------+\n",
      "|   AD_PRES|           President|     20080|     40000|\n",
      "|     AD_VP|Administration Vi...|     15000|     30000|\n",
      "|   AD_ASST|Administration As...|      3000|      6000|\n",
      "|    FI_MGR|     Finance Manager|      8200|     16000|\n",
      "|FI_ACCOUNT|          Accountant|      4200|      9000|\n",
      "|    AC_MGR|  Accounting Manager|      8200|     16000|\n",
      "|AC_ACCOUNT|   Public Accountant|      4200|      9000|\n",
      "|    SA_MAN|       Sales Manager|     10000|     20080|\n",
      "|    SA_REP|Sales Representative|      6000|     12008|\n",
      "|    PU_MAN|  Purchasing Manager|      8000|     15000|\n",
      "+----------+--------------------+----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trabajos.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uso de Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner Join\n",
    "\n",
    "    // Inner join implicito\n",
    "    Cuando las claves son iguales:\n",
    "    df1.join(df2, on=[\"clave\"])\n",
    "    Cuando las claves no son iguales:\n",
    "    df1.join(df2, df1(\"clave1\") == df2(\"clave2\"))\n",
    "    \n",
    "    // Inner join explicito\n",
    "    Cuando las claves son iguales:\n",
    "    df1.join(df2, on=[\"clave\"], how='inner')\n",
    "    Cuando las claves no son iguales:\n",
    "    df1.join(df2, df1(\"clave1\") == df2(\"clave2\"), \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_unida = paises.join(regiones, on=[\"region_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+--------------------+\n",
      "|REGION_ID|COUNTRY_ID|COUNTRY_NAME|         REGION_NAME|\n",
      "+---------+----------+------------+--------------------+\n",
      "|        2|        AR|   Argentina|            Americas|\n",
      "|        3|        AU|   Australia|                Asia|\n",
      "|        1|        BE|     Belgium|              Europe|\n",
      "|        2|        BR|      Brazil|            Americas|\n",
      "|        2|        CA|      Canada|            Americas|\n",
      "|        1|        CH| Switzerland|              Europe|\n",
      "|        3|        CN|       China|                Asia|\n",
      "|        1|        DE|     Germany|              Europe|\n",
      "|        1|        DK|     Denmark|              Europe|\n",
      "|        4|        EG|       Egypt|Middle East and A...|\n",
      "+---------+----------+------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabla_unida.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_unida = paises.join(regiones, paises[\"region_id\"] == regiones[\"region_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---------+---------+--------------------+\n",
      "|COUNTRY_ID|COUNTRY_NAME|REGION_ID|REGION_ID|         REGION_NAME|\n",
      "+----------+------------+---------+---------+--------------------+\n",
      "|        AR|   Argentina|        2|        2|            Americas|\n",
      "|        AU|   Australia|        3|        3|                Asia|\n",
      "|        BE|     Belgium|        1|        1|              Europe|\n",
      "|        BR|      Brazil|        2|        2|            Americas|\n",
      "|        CA|      Canada|        2|        2|            Americas|\n",
      "|        CH| Switzerland|        1|        1|              Europe|\n",
      "|        CN|       China|        3|        3|                Asia|\n",
      "|        DE|     Germany|        1|        1|              Europe|\n",
      "|        DK|     Denmark|        1|        1|              Europe|\n",
      "|        EG|       Egypt|        4|        4|Middle East and A...|\n",
      "+----------+------------+---------+---------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabla_unida.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left Join\n",
    "\n",
    "    Cuando las claves son iguales:\n",
    "    df1.join(df2, on=[\"clave\"], how='left_outer')\n",
    "    Cuando las claves no son iguales:\n",
    "    df1.join(df2, df1(\"clave1\") == df2(\"clave2\"), \"left_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_unida = paises.join(regiones, on=[\"region_id\"], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+--------------------+\n",
      "|REGION_ID|COUNTRY_ID|COUNTRY_NAME|         REGION_NAME|\n",
      "+---------+----------+------------+--------------------+\n",
      "|        2|        AR|   Argentina|            Americas|\n",
      "|        3|        AU|   Australia|                Asia|\n",
      "|        1|        BE|     Belgium|              Europe|\n",
      "|        2|        BR|      Brazil|            Americas|\n",
      "|        2|        CA|      Canada|            Americas|\n",
      "|        1|        CH| Switzerland|              Europe|\n",
      "|        3|        CN|       China|                Asia|\n",
      "|        1|        DE|     Germany|              Europe|\n",
      "|        1|        DK|     Denmark|              Europe|\n",
      "|        4|        EG|       Egypt|Middle East and A...|\n",
      "|        1|        FR|      France|              Europe|\n",
      "|        4|        IL|      Israel|Middle East and A...|\n",
      "|        3|        IN|       India|                Asia|\n",
      "|        1|        IT|       Italy|              Europe|\n",
      "|        3|        JP|       Japan|                Asia|\n",
      "|        4|        KW|      Kuwait|Middle East and A...|\n",
      "|        3|        ML|    Malaysia|                Asia|\n",
      "|        2|        MX|      Mexico|            Americas|\n",
      "|        4|        NG|     Nigeria|Middle East and A...|\n",
      "|        1|        NL| Netherlands|              Europe|\n",
      "+---------+----------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabla_unida.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rigth Join\n",
    "\n",
    "    Cuando las claves son iguales:\n",
    "    df1.join(df2, on=[\"clave\"], how='right')\n",
    "    Cuando las claves no son iguales:\n",
    "    df1.join(df2, df1(\"clave1\") == df2(\"clave2\"), \"right_outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_unida = paises.join(regiones, on=[\"region_id\"], how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('REGION_ID', 'int'),\n",
       " ('COUNTRY_ID', 'string'),\n",
       " ('COUNTRY_NAME', 'string'),\n",
       " ('REGION_NAME', 'string')]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_unida.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------------+-----------+\n",
      "|REGION_ID|COUNTRY_ID|        COUNTRY_NAME|REGION_NAME|\n",
      "+---------+----------+--------------------+-----------+\n",
      "|        1|        UK|      United Kingdom|     Europe|\n",
      "|        1|        NL|         Netherlands|     Europe|\n",
      "|        1|        IT|               Italy|     Europe|\n",
      "|        1|        FR|              France|     Europe|\n",
      "|        1|        DK|             Denmark|     Europe|\n",
      "|        1|        DE|             Germany|     Europe|\n",
      "|        1|        CH|         Switzerland|     Europe|\n",
      "|        1|        BE|             Belgium|     Europe|\n",
      "|        2|        US|United States of ...|   Americas|\n",
      "|        2|        MX|              Mexico|   Americas|\n",
      "+---------+----------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabla_unida.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Join\n",
    "\n",
    "    Cuando las claves son iguales:\n",
    "    df1.join(df2, on=[\"clave\"], how='full_outer')\n",
    "    Cuando las claves no son iguales:\n",
    "    df1.join(df2, df1(\"clave1\") == df2(\"clave2\"), \"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_unida = paises.join(regiones, on=[\"region_id\"], how='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('REGION_ID', 'int'),\n",
       " ('COUNTRY_ID', 'string'),\n",
       " ('COUNTRY_NAME', 'string'),\n",
       " ('REGION_NAME', 'string')]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla_unida.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------+-----------+\n",
      "|REGION_ID|COUNTRY_ID|  COUNTRY_NAME|REGION_NAME|\n",
      "+---------+----------+--------------+-----------+\n",
      "|        1|        BE|       Belgium|     Europe|\n",
      "|        1|        CH|   Switzerland|     Europe|\n",
      "|        1|        DE|       Germany|     Europe|\n",
      "|        1|        DK|       Denmark|     Europe|\n",
      "|        1|        FR|        France|     Europe|\n",
      "|        1|        IT|         Italy|     Europe|\n",
      "|        1|        NL|   Netherlands|     Europe|\n",
      "|        1|        UK|United Kingdom|     Europe|\n",
      "|        3|        AU|     Australia|       Asia|\n",
      "|        3|        CN|         China|       Asia|\n",
      "+---------+----------+--------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabla_unida.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajando un dataframe como Tabla de SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_unida.createOrReplaceTempView(\"Tabla1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------+--------------------+\n",
      "|REGION_ID|COUNTRY_ID|  COUNTRY_NAME|         REGION_NAME|\n",
      "+---------+----------+--------------+--------------------+\n",
      "|        1|        BE|       Belgium|              Europe|\n",
      "|        1|        CH|   Switzerland|              Europe|\n",
      "|        1|        DE|       Germany|              Europe|\n",
      "|        1|        DK|       Denmark|              Europe|\n",
      "|        1|        FR|        France|              Europe|\n",
      "|        1|        IT|         Italy|              Europe|\n",
      "|        1|        NL|   Netherlands|              Europe|\n",
      "|        1|        UK|United Kingdom|              Europe|\n",
      "|        3|        AU|     Australia|                Asia|\n",
      "|        3|        CN|         China|                Asia|\n",
      "|        3|        IN|         India|                Asia|\n",
      "|        3|        JP|         Japan|                Asia|\n",
      "|        3|        ML|      Malaysia|                Asia|\n",
      "|        3|        SG|     Singapore|                Asia|\n",
      "|        4|        EG|         Egypt|Middle East and A...|\n",
      "|        4|        IL|        Israel|Middle East and A...|\n",
      "|        4|        KW|        Kuwait|Middle East and A...|\n",
      "|        4|        NG|       Nigeria|Middle East and A...|\n",
      "|        4|        ZM|        Zambia|Middle East and A...|\n",
      "|        4|        ZW|      Zimbabwe|Middle East and A...|\n",
      "+---------+----------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"Select * from Tabla1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------------+-----------+\n",
      "|REGION_ID|COUNTRY_ID|  COUNTRY_NAME|REGION_NAME|\n",
      "+---------+----------+--------------+-----------+\n",
      "|        1|        BE|       Belgium|     Europe|\n",
      "|        1|        CH|   Switzerland|     Europe|\n",
      "|        1|        DE|       Germany|     Europe|\n",
      "|        1|        DK|       Denmark|     Europe|\n",
      "|        1|        FR|        France|     Europe|\n",
      "|        1|        IT|         Italy|     Europe|\n",
      "|        1|        NL|   Netherlands|     Europe|\n",
      "|        1|        UK|United Kingdom|     Europe|\n",
      "+---------+----------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"Select * from Tabla1 where Region_id = 1\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+---------+\n",
      "|first_name|department_id|hire_date|\n",
      "+----------+-------------+---------+\n",
      "|  Jennifer|           10| 17/09/03|\n",
      "|       Pat|           20| 17/08/05|\n",
      "|   Michael|           20| 17/02/04|\n",
      "|    Shelli|           30| 24/12/05|\n",
      "|     Sigal|           30| 24/07/05|\n",
      "+----------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empleados.select(\"first_name\", \"department_id\",\"hire_date\").sort([\"department_id\",\"hire_date\"], ascending = [1,0]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "paises_region = paises.join(regiones, on=[\"region_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+------------+\n",
      "|region_id|         region_name|country_name|\n",
      "+---------+--------------------+------------+\n",
      "|        2|            Americas|   Argentina|\n",
      "|        3|                Asia|   Australia|\n",
      "|        1|              Europe|     Belgium|\n",
      "|        2|            Americas|      Brazil|\n",
      "|        2|            Americas|      Canada|\n",
      "|        1|              Europe| Switzerland|\n",
      "|        3|                Asia|       China|\n",
      "|        1|              Europe|     Germany|\n",
      "|        1|              Europe|     Denmark|\n",
      "|        4|Middle East and A...|       Egypt|\n",
      "|        1|              Europe|      France|\n",
      "|        4|Middle East and A...|      Israel|\n",
      "|        3|                Asia|       India|\n",
      "|        1|              Europe|       Italy|\n",
      "|        3|                Asia|       Japan|\n",
      "|        4|Middle East and A...|      Kuwait|\n",
      "|        3|                Asia|    Malaysia|\n",
      "|        2|            Americas|      Mexico|\n",
      "|        4|Middle East and A...|     Nigeria|\n",
      "|        1|              Europe| Netherlands|\n",
      "+---------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "paises_region.select(\"region_id\",\"region_name\",\"country_name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
